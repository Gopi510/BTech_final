{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"importing the libraries which are needed\n\n\n\n"},{"metadata":{"trusted":true,"_uuid":"00833d394e3069216af171fd979c814e7e1e430d","_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"import os\nimport sys\nimport random\nimport warnings\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport cv2\n\nfrom tqdm import tqdm_notebook, tnrange\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras import backend as K\n\nimport tensorflow as tf\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true,"_uuid":"0e26e21ff39e8b2afc0003fec4e4f5269f61aa4c","_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"# Set some parameters\nim_width = 128\nim_height = 128\nim_chan = 1\npath_train = '../input/train/'\npath_test = '../input/test/'\nprint('Done!')\n","execution_count":2,"outputs":[{"output_type":"stream","text":"Done!\n","name":"stdout"}]},{"metadata":{"_uuid":"89455be399a79910334eb76beafc40bcdab08f83"},"cell_type":"markdown","source":"# Data Exploration"},{"metadata":{"trusted":true,"_uuid":"71bc5858327bdf6c54a9f99c0ac68e27abfcd567","_kg_hide-input":false,"_kg_hide-output":false},"cell_type":"code","source":"ids= ['1f1cc6b3a4','5b7c160d0d','6c40978ddf','7dfdf6eeb8','7e5a6e5013']\nplt.figure(figsize=(20,10))\nfor j, img_name in enumerate(ids):\n    q = j+1\n    img = load_img('../input/train/images/' + img_name + '.png')\n    img_mask = load_img('../input/train/masks/' + img_name + '.png')\n    \n    plt.subplot(1,2*(1+len(ids)),q*2-1)\n    plt.imshow(img)\n    plt.subplot(1,2*(1+len(ids)),q*2)\n    plt.imshow(img_mask)\nplt.show()\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61fa14e7421411a0ca943a1a36e77cbef2ddcbd2"},"cell_type":"markdown","source":"setting the path where the images used for training and testing are located in train_ids and test_ids"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"97114b7b4f28347130dc3e44af5469d6efdf7ab1"},"cell_type":"code","source":"train_ids = next(os.walk(path_train+\"images\"))[2]\ntest_ids = next(os.walk(path_test+\"images\"))[2]\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8f02165966489c8a21bb7127bb88e7cf607599d"},"cell_type":"code","source":"# Get and resize train images and masks\nX_train = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.uint8)\nY_train = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.bool)\nprint('Getting and resizing train images and masks ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n    path = path_train\n    img = load_img(path + '/images/' + id_)\n    x = img_to_array(img)[:,:,1]\n    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n    X_train[n] = x\n    mask = img_to_array(load_img(path + '/masks/' + id_))[:,:,1]\n    Y_train[n] = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)\n\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"faf6ea42655fb0f5ee8994a65a7c3bef888ef1ae"},"cell_type":"code","source":"# Check if training data looks all right\nix = random.randint(0, len(train_ids))\nplt.imshow(np.dstack((X_train[ix],X_train[ix],X_train[ix])))\nplt.show()\ntmp = np.squeeze(Y_train[ix]).astype(np.float32)\nplt.imshow(np.dstack((tmp,tmp,tmp)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0d66a11a8d8d48e16640307185062f5494c1f5b6"},"cell_type":"markdown","source":"# Train Model\n"},{"metadata":{"trusted":true,"_uuid":"b4716a2112dfb71c75e60bff90cb17836f78bf66"},"cell_type":"code","source":"# Define IoU metric\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t)\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score)\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0e7c423ccf5145d6ac991dad85262540735e4dfe"},"cell_type":"markdown","source":" Building the sequential Model. The U-Net is basically looking like an Auto-Encoder with shortcuts. \n\nWe're also sprinkling in some earlystopping to prevent overfitting. If you're running this on kaggle, this is the point, we want  GPU support."},{"metadata":{"trusted":true,"_uuid":"58e87797db5bb02b8f0ad6a0af6592e94f9f8b3f"},"cell_type":"code","source":"# Build U-Net model\ninputs = Input((im_height, im_width, im_chan))\ns = Lambda(lambda x: x / 255) (inputs)\n\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\np4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\nc5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n\nu6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\nu6 = concatenate([u6, c4])\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\nc6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n\nu7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c3])\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\nc7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n\nu8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c2])\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\nc8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n\nu9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\nu9 = concatenate([u9, c1], axis=3)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\nc9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\nmodel = Model(inputs=[inputs], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nearlystopper = EarlyStopping(patience=5, verbose=1)\ncheckpointer = ModelCheckpoint('model-tgs-salt-1.h5', verbose=1 , save_best_only=True)\nresults = model.fit(X_train, Y_train, validation_split=0.1, batch_size=4, epochs=30, \n                    callbacks=[earlystopper, checkpointer])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot(hist, epochs):\n    # visualizing losses and accuracy\n    train_loss = hist.history['loss']\n    val_loss = hist.history['val_loss']\n    train_acc = hist.history['mean_iou']\n    val_acc = hist.history['val_mean_iou']\n    xc = range(epochs)\n\n    plt.figure(1, figsize=(7, 5))\n    plt.plot(xc, train_loss)\n    plt.plot(xc, val_loss)\n    plt.xlabel('num of Epochs')\n    plt.ylabel('loss')\n    plt.title('train_loss vs val_loss')\n    plt.grid(True)\n    plt.legend(['train', 'val'])\n    # print plt.style.available # use bmh, classic,ggplot for big pictures\n    plt.style.use(['classic'])\n\n    plt.figure(2, figsize=(7, 5))\n    plt.plot(xc, train_acc)\n    plt.plot(xc, val_acc)\n    plt.xlabel('num of Epochs')\n    plt.ylabel('mean_iou')\n    plt.title('train_mean_iou vs val_mean_iou')\n    plt.grid(True)\n    plt.legend(['train', 'val'], loc=4)\n    # print plt.style.available # use bmh, classic,ggplot for big pictures\n    plt.style.use(['classic'])\nplot(results,25)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5ab8516fb8ab135872dd4f4b895b5d76206df1fa"},"cell_type":"markdown","source":"# Test Data\nFirst we'll get the test data. This takes a while, it's 18000 samples."},{"metadata":{"trusted":true,"_uuid":"c6d376a5ed9fa0ff708299f55a0a8ed8b8471137"},"cell_type":"code","source":"# Get and resize test images\nX_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.uint8)\nsizes_test = []\nprint('Getting and resizing test images ... ')\nsys.stdout.flush()\nfor n, id_ in tqdm_notebook(enumerate(test_ids), total=len(test_ids)):\n    path = path_test\n    img = load_img(path + '/images/' + id_)\n    x = img_to_array(img)[:,:,1]\n    sizes_test.append([x.shape[0], x.shape[1]])\n    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n    X_test[n] = x\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2316034edcb7227673fd9b69264ca9c0d0e87f14"},"cell_type":"code","source":"# Predict on train, val and test\nmodel = load_model('model-tgs-salt-1.h5', custom_objects={'mean_iou': mean_iou})\npreds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\npreds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\npreds_test = model.predict(X_test, verbose=1)\n\n# Threshold predictions\npreds_train_t = (preds_train > 0.5).astype(np.uint8)\npreds_val_t = (preds_val > 0.5).astype(np.uint8)\npreds_test_t = (preds_test > 0.14).astype(np.uint8)\nmodel.evaluate(X_test,preds_test_t,batch_size=2,verbose=1,steps=None)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af64790cdb7e5beb05fc34635cdf092124d7dc20","_kg_hide-input":false},"cell_type":"code","source":"# Create list of upsampled test masks\npreds_test_upsampled = []\nfor i in tnrange(len(preds_test)):\n    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n                                       (sizes_test[i][0], sizes_test[i][1]), \n                                       mode='constant', preserve_range=True))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7da5a47444df98205dd7039223868b5d67f15400"},"cell_type":"code","source":"preds_test_upsampled[0].shape\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"24defa25c00d0d91b38e559515e78c63f4d26e2b"},"cell_type":"markdown","source":"We'll look at it again, just to be sure."},{"metadata":{"trusted":true,"_uuid":"6302c46fc76d8a43cb87d01c43c60c3c8f0ac98b"},"cell_type":"code","source":"# Perform a sanity check on some random training samples\nix = random.randint(0, len(preds_train_t))\nplt.imshow(np.dstack((X_train[ix],X_train[ix],X_train[ix])))\nplt.show()\ntmp = np.squeeze(Y_train[ix]).astype(np.float32)\nplt.imshow(np.dstack((tmp,tmp,tmp)))\nplt.show()\ntmp = np.squeeze(preds_train_t[ix]).astype(np.float32)\nplt.imshow(np.dstack((tmp,tmp,tmp)))\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"844cded40edc71652bc5b26852245e37f46f6448"},"cell_type":"markdown","source":"\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}